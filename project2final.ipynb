{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8281b6f8",
   "metadata": {},
   "source": [
    "# Machine Learning in Python - Project 2\n",
    "\n",
    "Alfie Plant, Markus Emmott, Oscar Youngman, Ashe Raymond-Barker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821233d2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "*Install any packages here, define any functions if neeed, and load data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e1ba94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional libraries or submodules below\n",
    "\n",
    "# Data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting defaults\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "plt.rcParams['figure.dpi'] = 80\n",
    "\n",
    "# sklearn modules\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from sklearn.metrics import RocCurveDisplay, roc_auc_score\n",
    "from sklearn.metrics import PrecisionRecallDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28603fe7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Brief discussion of problem and approaches used\n",
    "\n",
    "### Data Overview\n",
    "\n",
    "Data type of each feature and a short description, indicate features that can be excluded.\n",
    "\n",
    "Columns that have been removed:\n",
    "\n",
    "`ppmt_pnlty`, `prod_type`, `id_loan`, `id_loan_rr` and `io_ind`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b59b639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"freddiemac.csv\", low_memory=False)\n",
    "d = d.drop(columns=['id_loan', 'id_loan_rr', 'io_ind', 'prod_type', 'ppmt_pnlty'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06de4af",
   "metadata": {},
   "source": [
    "\n",
    "### Missing Data\n",
    "\n",
    "The data includes approximately 20,000 null values for the **cd_msa** information. Despite this, there is no missing information on **zipcode**. As a result, we have decided to use zipcode data in analysis. This will be discussed in more detail in exploratory data analysis.\n",
    "The remaining features that contain null values are **flag_sc**, and **rr_ind**, however these are categorical variables that take NaN to refer to 'No'. All NaN entries have been replaced with 'N'.\n",
    "\n",
    "There are 41 missing Credit Scores in the dataset. Out of these, 3 loans were defaults. Since the dataset does not contain many defaults, we do not want to exclude this information and we will proceed by ***add detail here...***. Only one observation is not available for the mortgage insurance percentage and given this loan was not a default, we will exclude it from the data set. There are 6 missing observations for combined loan-to-value, and 2 of these are the missing values for loan-to-value, which occurs when the loanee has no other loans. None of these loans were defaults, so they have been excluded.\n",
    "\n",
    "There are 2,412 missing values for the debt-to-income ratio, and more notably, a disproportinal number of these observations are loans that have defaulted. When debt-to-income ratio is greater than 65%, it is classified as a missing value. These are loans where the monthly debt payments are greater than 65% of monthly income of the loanee suggesting that they are higher-risk loans. To deal with this we have discretised debt-to-income and encoded it ordinally. We have used cross-validation to determine a reasonable choice for the number of bins as 10. ***check this, should we do CV using a logistic model which typically has bad performance***\n",
    "\n",
    "We interpret the value of 9 for the program indicator as Not Applicable meaning that the loan is not part of a program. There could be missing data embedded within this, however since this category acts as a baseline associated to no programs, then this assumption does not lose any information. Finally, there are 125 values missing for property value. None of these are defaults, so they have been excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555ee868",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['flag_sc'] = d['flag_sc'].fillna('N')\n",
    "d['rr_ind'] = d['rr_ind'].fillna('N')\n",
    "d = d[d['fico'] != 9999] # removed missing credit scores for now but perhaps we should reconsider\n",
    "d = d[d['mi_pct'] != 999]\n",
    "d = d[d['cltv'] != 999]\n",
    "d = d[d['property_val'] != 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e03f9c",
   "metadata": {},
   "source": [
    "### Data Split\n",
    "\n",
    "***To avoid any data leakage, the dataset is split into training and test sets from this point onwards.***\n",
    "\n",
    "We will separate active loans from non-active loans. The non-active loans will be separated a training set (70%) to build the model, a validation set to tune the model (15%), and finally a test set (15%). Once the final model has been determined, it will be used to offer insight on active loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c75934e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "active = d[d['loan_status'] == 'active']\n",
    "nonactive = d[d['loan_status'] != 'active']\n",
    "\n",
    "# Feature matrix and response vector\n",
    "X, y = nonactive.drop(['loan_status'], axis=1), nonactive['loan_status']\n",
    "\n",
    "# Convert to numpy array\n",
    "X = X.values\n",
    "\n",
    "# Encode default\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Naively split the data into train and test sets \n",
    "X_train, X_tv, y_train, y_tv = train_test_split(X, y, shuffle= True,\n",
    "                                                    test_size = 0.3, random_state=1112, stratify=y)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_tv, y_tv, shuffle= True,\n",
    "                                                    test_size = 0.5, random_state=1112, stratify=y_tv)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df_train = pd.DataFrame(np.concatenate([X_train, y_train.reshape(-1, 1)], axis=1), columns=nonactive.columns)\n",
    "df_test = pd.DataFrame(np.concatenate([X_test, y_test.reshape(-1, 1)], axis=1), columns=nonactive.columns)\n",
    "df_val = pd.DataFrame(np.concatenate([X_test, y_test.reshape(-1, 1)], axis=1), columns=nonactive.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4bc461",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "### Categorical Data\n",
    "\n",
    "### Numerical Data\n",
    "\n",
    "### Geographical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc9fe39",
   "metadata": {},
   "source": [
    "# Model Fitting and Tuning\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "### Linear SVM\n",
    "\n",
    "### Non-Linear SVM\n",
    "\n",
    "### Random Forests\n",
    "\n",
    "### Neural Networks\n",
    "\n",
    "### Final Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a9c84",
   "metadata": {},
   "source": [
    "# Discussion & Conclusions\n",
    "\n",
    "*In this section you should provide a general overview of your final model, its performance, and reliability. You should discuss what the implications of your model are in terms of the included features, estimated parameters and relationships, predictive performance, and anything else you think is relevant.*\n",
    "\n",
    "*This should be written with a target audience of a banking official, who is understands the issues associated with mortgage defaults but may only have university level mathematics (not necessarily postgraduate statistics or machine learning). Your goal should be to highlight to this audience how your model can useful. You should also discuss potential limitations or directions of future improvement of your model.*\n",
    "\n",
    "*Finally, you should include recommendations on factors that may increase the risk of default, which may be useful for the companies to improve their understanding of\n",
    "mortgage defaults, and also to explain their decisions to clients and regulatory bodies. You should also use your model to inform the company of any active loans that are at risk of default.*\n",
    "\n",
    "*Keep in mind that a negative result, i.e. a model that does not work well predictively, that is well explained and justified in terms of why it failed will likely receive higher marks than a model with strong predictive performance but with poor or incorrect explinations / justifications.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb8539f",
   "metadata": {},
   "source": [
    "# Generative AI statement\n",
    "\n",
    "*Include a statement on how generative AI was used in the project and report.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db6349",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "*Include references if any*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3625a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following to render to PDF\n",
    "!jupyter nbconvert --to pdf project2.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
